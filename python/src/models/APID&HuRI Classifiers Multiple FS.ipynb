{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16730ee",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm_notebook\n",
    "import classifiers\n",
    "import importlib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5838ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "(function(on) {\n",
    "const e=$( \"<a>Setup failed</a>\" );\n",
    "const ns=\"js_jupyter_suppress_warnings\";\n",
    "var cssrules=$(\"#\"+ns);\n",
    "if(!cssrules.length) cssrules = $(\"<style id='\"+ns+\"' type='text/css'>div.output_stderr { } </style>\").appendTo(\"head\");\n",
    "e.click(function() {\n",
    "    var s='Showing';  \n",
    "    cssrules.empty()\n",
    "    if(on) {\n",
    "        s='Hiding';\n",
    "        cssrules.append(\"div.output_stderr, div[data-mime-type*='.stderr'] { display:none; }\");\n",
    "    }\n",
    "    e.text(s+' warnings (click to toggle)');\n",
    "    on=!on;\n",
    "}).click();\n",
    "$(element).append(e);\n",
    "})(true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88438d25",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b219c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_labels_df = pd.read_csv('../../data/processed/reactome_labels_apid_huri.csv', header = None)\n",
    "reactome_labels = reactome_labels_df.transpose().to_numpy(dtype='int')\n",
    "reactome_labels_df.index= pd.read_csv(\"../../data/processed/metrics/process_hypergeometric_apid_huri.csv\", sep=',', header=0, index_col=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_hypergeometric = np.array(pd.read_csv(\"../../data/processed/metrics/process_hypergeometric_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_closeness = np.array(pd.read_csv(\"../../data/processed/metrics/process_closeness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_betweenness = np.array(pd.read_csv(\"../../data/processed/metrics/process_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_rwr = np.array(pd.read_csv(\"../../data/processed/metrics/process_rwr_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_fraction_betweenness = np.array(pd.read_csv(\"../../data/processed/metrics/process_fraction_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "\n",
    "#reactome_hypergeometric_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_hyper_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_closeness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_closeness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_betweenness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_rwr_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_rwr_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_fraction_betweenness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_fraction_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "\n",
    "#reactome_hypergeometric_protein80 = pd.read_csv(\"../../data/processed/metrics/process_protein80_hyper_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_closeness_protein80 = pd.read_csv(\"../../data/processed/metrics/process_protein80_closeness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_betweenness_protein80 = pd.read_csv(\"../../data/processed/metrics/process_protein80_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_rwr_protein80 = pd.read_csv(\"../../data/processed/metrics/process_protein80_rwr_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "#reactome_fraction_betweenness_protein80 = pd.read_csv(\"../../data/processed/metrics/process_protein80_fraction_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d908579",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_hypergeometric_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_hyper_fs_apid_huri.csv\", sep=',', header=0)\n",
    "reactome_closeness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_closeness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "reactome_betweenness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_betweenness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "reactome_rwr_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_rwr_fs_apid_huri.csv\", sep=',', header=0)\n",
    "reactome_fraction_betweenness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "\n",
    "#reactome_hypergeometric_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_closeness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_betweenness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_rwr_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_fraction_betweenness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "\n",
    "#reactome_hypergeometric_protein80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_protein80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_closeness_protein80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_protein80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_betweenness_protein80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_protein80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_rwr_protein80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_protein80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "#reactome_fraction_betweenness_protein80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_protein80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_hypergeometric_test_index = pd.read_csv(\"../../data/processed/fs/reactome_hyper_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "reactome_closeness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_closeness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "reactome_betweenness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_betweenness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "reactome_rwr_test_index = pd.read_csv(\"../../data/processed/fs/reactome_rwr_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "reactome_fraction_betweenness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "\n",
    "#reactome_hypergeometric_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_closeness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_betweenness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_rwr_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_fraction_betweenness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "\n",
    "#reactome_hypergeometric_protein80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_protein80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_closeness_protein80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_protein80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_betweenness_protein80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_protein80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_rwr_protein80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_protein80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "#reactome_fraction_betweenness_protein80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_protein80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1370b31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi80_hyper_list = []\n",
    "ppi80_closeness_list = []\n",
    "ppi80_betweenness_list = []\n",
    "ppi80_fraction_betweenness_list = []\n",
    "ppi80_rwr_list = []\n",
    "label_list = []\n",
    "\n",
    "for i, df in reactome_hypergeometric_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_hyper_list.append(df)\n",
    "    label_list.append(reactome_labels_df[reactome_labels_df.index.isin(df.index)])\n",
    "\n",
    "for i, df in reactome_closeness_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_closeness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_betweenness_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_betweenness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_rwr_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_rwr_list.append(df)\n",
    "    \n",
    "for i, df in reactome_fraction_betweenness_80.groupby(level=0):\n",
    "    df.set_index('index', inplace=True)\n",
    "    ppi80_fraction_betweenness_list.append(df)\n",
    "    \n",
    "protein80_hyper_list = []\n",
    "protein80_closeness_list = []\n",
    "protein80_betweenness_list = []\n",
    "protein80_rwr_list = []\n",
    "protein80_fraction_betweenness_list = []\n",
    "protein_label_list = []\n",
    "\n",
    "for i, df in reactome_hypergeometric_protein80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    protein80_hyper_list.append(df)\n",
    "    protein_label_list.append(reactome_labels_df[reactome_labels_df.index.isin(df.index)])\n",
    "    \n",
    "for i, df in reactome_closeness_protein80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    protein80_closeness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_betweenness_protein80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    protein80_betweenness_list.append(df)\n",
    "\n",
    "for i, df in reactome_rwr_protein80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    protein80_rwr_list.append(df)\n",
    "    \n",
    "for i, df in reactome_fraction_betweenness_protein80.groupby(level=0):\n",
    "    df.set_index('index', inplace=True)\n",
    "    protein80_fraction_betweenness_list.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95499cb",
   "metadata": {},
   "source": [
    "# 2. Classification Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e955f",
   "metadata": {},
   "source": [
    "## 2.1. Classification with 11 (10 + self) best processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917b165",
   "metadata": {},
   "source": [
    "### 2.1.1. Complete Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9915d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "\n",
    "clf = LogisticRegression(random_state=22)\n",
    "\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "\n",
    "hyper_lgr_clf, hyper_lgr_proba_clf, hyper_cv, hyper_n_fs = classifiers.multiple_fs_classifier(clf, parameters, reactome_hypergeometric, reactome_hypergeometric_test_index, reactome_hypergeometric_fs_ar, reactome_labels_df, jobs=2)\n",
    "hyper_lgr_clf.to_csv('../../models/apid_huri_multiple_fs/process/binary/disease_hypergeometric_lgr.csv', index=False)\n",
    "hyper_lgr_proba_clf.to_csv('../../models/apid_huri_multiple_fs/process/probability/disease_hypergeometric_lgr_proba.csv', index=False)\n",
    "with open('../../models/apid_huri_multiple_fs/process/cv_results/hypergeometric.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in hyper_cv))\n",
    "with open(\"../../models/apid_huri_multiple_fs/process/n_fs/hypergeometric.txt\", \"w\") as f:\n",
    "    for s in hyper_n_fs:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "rwr_lgr_clf, rwr_lgr_proba_clf, rwr_cv, rwr_n_fs = classifiers.multiple_fs_classifier(clf, parameters, reactome_rwr, reactome_rwr_test_index, reactome_rwr_fs_ar, reactome_labels_df, jobs=20)\n",
    "rwr_lgr_clf.to_csv('../../models/apid_huri_multiple_fs/process/binary/disease_rwr_lgr.csv', index=False)\n",
    "rwr_lgr_proba_clf.to_csv('../../models/apid_huri_multiple_fs/process/probability/disease_rwr_lgr_proba.csv', index=False)\n",
    "with open('../../models/apid_huri_multiple_fs/process/cv_results/rwr.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in rwr_cv))\n",
    "with open(\"../../models/apid_huri_multiple_fs/process/n_fs/rwr.txt\", \"w\") as f:\n",
    "    for s in rwr_n_fs:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91671af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "reactome_closeness_fs = process_selector(reactome_closeness_fs_ar, '10')\n",
    "closeness_lgr_clf, closeness_lgr_proba_clf, closeness_cv, closeness_n_fs = classifiers.multiple_fs_classifier(clf, parameters, reactome_closeness, reactome_closeness_test_index, reactome_closeness_fs_ar, reactome_labels, jobs=20)\n",
    "closeness_lgr_clf.to_csv('../../models/apid_huri_multiple_fs/disease/binary/disease_closeness_lgr.csv', index=False)\n",
    "closeness_lgr_proba_clf.to_csv('../../models/apid_huri_multiple_fs/disease/probability/disease_closeness_lgr_proba.csv', index=False)\n",
    "with open('../../models/apid_huri_multiple_fs/disease/cv_results/closeness.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in closeness_cv))\n",
    "with open(\"../../models/apid_huri_multiple_fs/disease/n_fs/closeness.txt\", \"w\") as f:\n",
    "    for s in closeness_n_fs:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c11337",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "betweenness_lgr_clf, betweenness_lgr_proba_clf, betweenness_cv, betweenness_n_fs = classifiers.multiple_fs_classifier(clf, parameters, reactome_betweenness, reactome_betweenness_test_index, reactome_betweenness_fs_ar, reactome_labels_df, jobs=20)\n",
    "betweenness_lgr_clf.to_csv('../../models/apid_huri_multiple_fs/process/binary/disease_betweenness_lgr.csv', index=False)\n",
    "betweenness_lgr_proba_clf.to_csv('../../models/apid_huri_multiple_fs/process/probability/disease_betweenness_lgr_proba.csv', index=False)\n",
    "with open('../../models/apid_huri_multiple_fs/process/cv_results/betweenness.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in betweenness_cv))\n",
    "with open(\"../../models/apid_huri_multiple_fs/process/n_fs/betweenness.txt\", \"w\") as f:\n",
    "    for s in betweenness_n_fs:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "fraction_betweenness_lgr_clf, fraction_betweenness_lgr_proba_clf, fraction_betweenness_cv, fraction_betweenness_n_fs = classifiers.multiple_fs_classifier(clf, parameters, reactome_fraction_betweenness, reactome_fraction_betweenness_test_index, reactome_fraction_betweenness_fs_ar, reactome_labels_df, jobs=20)\n",
    "fraction_betweenness_lgr_clf.to_csv('../../models/apid_huri_multiple_fs/process/binary/disease_fraction_betweenness_lgr.csv', index=False)\n",
    "fraction_betweenness_lgr_proba_clf.to_csv('../../models/apid_huri_multiple_fs/process/probability/disease_fraction_betweenness_lgr.csv', index=False)\n",
    "with open('../../models/apid_huri_multiple_fs/process/cv_results/fraction_betweenness.txt', 'w') as fp:\n",
    "    fp.write('\\n'.join('%s %s' % x for x in fraction_betweenness_cv))\n",
    "with open(\"../../models/apid_huri_multiple_fs/process/n_fs/fraction_betweenness.txt\", \"w\") as f:\n",
    "    for s in fraction_betweenness_n_fs:\n",
    "        f.write(str(s) +\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72237216",
   "metadata": {},
   "source": [
    "### 2.1.2. Reduced Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9f7bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "hyper_80_lgr, hyper_80_lgr_proba, hyper_80_cv, hyper_80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, ppi80_hyper_list, reactome_hypergeometric_80_test_index, reactome_hypergeometric_80_fs_ar, label_list)\n",
    "hyper_80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/hypergeometric_80_lgr.csv', index=False)\n",
    "hyper_80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/hypergeometric_80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41bae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "hyper_protein80_lgr, hyper_protein80_lgr_proba, hyper_protein80_cv, hyper_protein80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, protein80_hyper_list, reactome_hypergeometric_protein80_test_index, reactome_hypergeometric_protein80_fs_ar, protein_label_list)\n",
    "hyper_protein80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/hypergeometric_protein80_lgr.csv', index=False)\n",
    "hyper_protein80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/hypergeometric_protein80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "closeness_80_lgr, closeness_80_lgr_proba, closeness_80_cv, closeness_80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, ppi80_closeness_list, reactome_closeness_80_test_index, reactome_closeness_80_fs_ar, label_list)\n",
    "closeness_80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/closeness_80_lgr.csv', index=False)\n",
    "closeness_80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/closeness_80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ca1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "closeness_protein80_lgr, closeness_protein80_lgr_proba, closeness_protein80_cv, closeness_protein80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, protein80_closeness_list, reactome_closeness_protein80_test_index, reactome_closeness_protein80_fs_ar, protein_label_list)\n",
    "closeness_protein80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/closeness_protein80_lgr.csv', index=False)\n",
    "closeness_protein80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/closeness_protein80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "rwr_80_lgr, rwr_80_lgr_proba, rwr_80_cv, rwr_80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, ppi80_rwr_list, reactome_rwr_80_test_index, reactome_rwr_80_fs_ar, label_list)\n",
    "rwr_80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/rwr_80_lgr.csv', index=False)\n",
    "rwr_80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/rwr_80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754734a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "rwr_protein80_lgr, rwr_protein80_lgr_proba, rwr_protein80_cv, rwr_protein80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, protein80_rwr_list, reactome_rwr_protein80_test_index, reactome_rwr_protein80_fs_ar, protein_label_list)\n",
    "rwr_protein80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/rwr_protein80_lgr.csv', index=False)\n",
    "rwr_protein80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/rwr_protein80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a85d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "fraction_betweenness_80_lgr, fraction_betweenness_80_lgr_proba, fraction_betweenness_80_cv, fraction_betweenness_80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, ppi80_fraction_betweenness_list, reactome_fraction_betweenness_80_test_index, reactome_fraction_betweenness_80_fs_ar, label_list)\n",
    "fraction_betweenness_80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/fraction_betweenness_80_lgr.csv', index=False)\n",
    "fraction_betweenness_80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/fraction_betweenness_80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e78b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "fraction_betweenness_protein80_lgr, fraction_betweenness_protein80_lgr_proba, fraction_betweenness_protein80_cv, fraction_betweenness_protein80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, protein80_fraction_betweenness_list, reactome_fraction_betweenness_protein80_test_index, reactome_fraction_betweenness_protein80_fs_ar, protein_label_list)\n",
    "fraction_betweenness_protein80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/fraction_betweenness_protein80_lgr.csv', index=False)\n",
    "fraction_betweenness_protein80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/fraction_betweenness_protein80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c89ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "betweenness_80_lgr, betweenness_80_lgr_proba, betweenness_80_cv, betweenness_80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, ppi80_betweenness_list, reactome_betweenness_80_test_index, reactome_betweenness_80_fs_ar, label_list)\n",
    "betweenness_80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/betweenness_80_lgr.csv', index=False)\n",
    "betweenness_80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/betweenness_80_lgr.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d90b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "betweenness_protein80_lgr, betweenness_protein80_lgr_proba, betweenness_protein80_cv, betweenness_protein80_n_fs = classifiers.reduced_classifier_multiple_fs(clf, parameters, protein80_betweenness_list, reactome_betweenness_protein80_test_index, reactome_betweenness_protein80_fs_ar, protein_label_list)\n",
    "betweenness_protein80_lgr.to_csv('../../models/apid_huri_multiple_fs/process/binary/betweenness_protein80_lgr.csv', index=False)\n",
    "betweenness_protein80_lgr_proba.to_csv('../../models/apid_huri_multiple_fs/process/probability/betweenness_protein80_lgr.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
