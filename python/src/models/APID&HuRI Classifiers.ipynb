{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16730ee",
   "metadata": {},
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebce7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import classifiers\n",
    "import importlib\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5838ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "(function(on) {\n",
    "const e=$( \"<a>Setup failed</a>\" );\n",
    "const ns=\"js_jupyter_suppress_warnings\";\n",
    "var cssrules=$(\"#\"+ns);\n",
    "if(!cssrules.length) cssrules = $(\"<style id='\"+ns+\"' type='text/css'>div.output_stderr { } </style>\").appendTo(\"head\");\n",
    "e.click(function() {\n",
    "    var s='Showing';  \n",
    "    cssrules.empty()\n",
    "    if(on) {\n",
    "        s='Hiding';\n",
    "        cssrules.append(\"div.output_stderr, div[data-mime-type*='.stderr'] { display:none; }\");\n",
    "    }\n",
    "    e.text(s+' warnings (click to toggle)');\n",
    "    on=!on;\n",
    "}).click();\n",
    "$(element).append(e);\n",
    "})(true);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88438d25",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab1581",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_hypergeometric = np.array(pd.read_csv(\"../../data/processed/metrics/process_hypergeometric_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_closeness = np.array(pd.read_csv(\"../../data/processed/metrics/process_closeness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_betweenness = np.array(pd.read_csv(\"../../data/processed/metrics/process_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_rwr = np.array(pd.read_csv(\"../../data/processed/metrics/process_rwr_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "reactome_fraction_betweenness = np.array(pd.read_csv(\"../../data/processed/metrics/process_fraction_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0).transpose())\n",
    "\n",
    "#reactome_bridge = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/related/reactome_bridge_fs_apid_huri.csv\", sep=',', header=0).transpose(),429,axis=0))\n",
    "#reactome_scp = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/related/reactome_scp_fs_apid_huri.csv\", sep=',', header=0).transpose(),429,axis=0))\n",
    "#reactome_slb = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/related/reactome_slb_fs_apid_huri.csv\", sep=',', header=0).transpose(),429,axis=0))\n",
    "\n",
    "reactome_hypergeometric_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_hyper_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "reactome_closeness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_closeness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "reactome_betweenness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "reactome_fraction_betweenness_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_fraction_betweenness_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "reactome_rwr_80 = pd.read_csv(\"../../data/processed/metrics/process_ppi80_rwr_apid_huri.csv\", sep=',', header=0, index_col=0)\n",
    "\n",
    "#reactome_bridge_80 = np.array_split(np.load('../../data/processed/fs/reactome_bridge_80_fs_apid_huri.npz', allow_pickle=True)['arr_0'],10,axis=0)\n",
    "#reactome_scp_80 = np.array_split(np.load('../../data/processed/fs/reactome_scp_80_fs_apid_huri.npz', allow_pickle=True)['arr_0'],10,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b0da42",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_labels_df = pd.read_csv('../../data/processed/reactome_labels_apid_huri.csv', header=None)\n",
    "reactome_labels = reactome_labels_df.transpose().to_numpy(dtype='int')\n",
    "reactome_labels_df.columns=pd.read_csv(\"../../data/processed/metrics/process_hypergeometric_apid_huri.csv\", sep=',', header=0, index_col=0).columns\n",
    "reactome_labels_df.index=pd.read_csv(\"../../data/processed/metrics/process_hypergeometric_apid_huri.csv\", sep=',', header=0, index_col=0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi80_hyper_list = []\n",
    "ppi80_closeness_list = []\n",
    "ppi80_betweenness_list = []\n",
    "ppi80_fraction_betweenness_list = []\n",
    "ppi80_rwr_list = []\n",
    "label_list = []\n",
    "\n",
    "for i, df in reactome_hypergeometric_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_hyper_list.append(df)\n",
    "    label_list.append(reactome_labels_df[reactome_labels_df.index.isin(df.index)])\n",
    "\n",
    "for i, df in reactome_closeness_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_closeness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_betweenness_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_betweenness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_fraction_betweenness_80.groupby(level=0):\n",
    "    df.set_index('index', inplace=True)\n",
    "    ppi80_fraction_betweenness_list.append(df)\n",
    "    \n",
    "for i, df in reactome_rwr_80.groupby(level=0):\n",
    "    df.set_index('level_1', inplace=True)\n",
    "    ppi80_rwr_list.append(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ffcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi80_bridge_list = []\n",
    "ppi80_scp_list = []\n",
    "\n",
    "for df in range(len(reactome_bridge_80)):\n",
    "    bridge = reactome_bridge_80[df][~np.any(np.isnan(reactome_bridge_80[df]), axis=1)]\n",
    "    ppi80_bridge_list.append(np.array_split(bridge, 429, axis=1))\n",
    "    \n",
    "for df in range(len(reactome_bridge_80)):\n",
    "    scp = reactome_bridge_80[df][~np.any(np.isnan(reactome_bridge_80[df]), axis=1)]\n",
    "    ppi80_scp_list.append(np.array_split(scp, 429, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d908579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reactome_hypergeometric_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_hyper_fs_apid_huri.csv\", sep=',', header=0)\n",
    "#reactome_closeness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_closeness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "#reactome_betweenness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_betweenness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "#reactome_rwr_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_rwr_fs_apid_huri.csv\", sep=',', header=0)\n",
    "#reactome_fraction_betweenness_fs_ar = pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_fs_apid_huri.csv\", sep=',', header=0)\n",
    "\n",
    "reactome_hypergeometric_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "reactome_closeness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "reactome_betweenness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "reactome_rwr_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))\n",
    "reactome_fraction_betweenness_80_fs_ar = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_80_fs_apid_huri.csv\", sep=',', header=0).transpose(),10, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf21d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reactome_hypergeometric_test_index = pd.read_csv(\"../../data/processed/fs/reactome_hyper_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "#reactome_closeness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_closeness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "#reactome_betweenness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_betweenness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "#reactome_rwr_test_index = pd.read_csv(\"../../data/processed/fs/reactome_rwr_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "#reactome_fraction_betweenness_test_index = pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_test_apid_huri.csv\", sep=',', header=0).transpose().to_numpy(dtype='int')-1\n",
    "\n",
    "reactome_hypergeometric_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_hyper_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "reactome_closeness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_closeness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "reactome_betweenness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_betweenness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "reactome_rwr_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_rwr_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1\n",
    "reactome_fraction_betweenness_80_test_index = np.array(np.array_split(pd.read_csv(\"../../data/processed/fs/reactome_fraction_betweenness_80_test_apid_huri.csv\", sep=',', header=0).transpose(), 10, axis = 1)).astype(int) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee0172",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactome_hypergeometric_80_test_index.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95499cb",
   "metadata": {},
   "source": [
    "# 2. Classification Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae43e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_selector(fs_df, method):\n",
    "    fs =[]\n",
    "    for column in range(len(fs_df.columns)):\n",
    "        process = fs_df.columns[column]\n",
    "        if method == 'outlier':\n",
    "            Q3 = fs_df[process].quantile(0.75)\n",
    "            Q1 = fs_df[process].quantile(0.25)\n",
    "            IQR = Q3 - Q1\n",
    "            threshold = Q3 + 1.5*IQR\n",
    "            if len(fs_df[fs_df[process]>threshold].index) > 0:\n",
    "                fs.append(np.array(fs_df[fs_df[process]>threshold].index))\n",
    "            else:\n",
    "                fs.append(np.array(fs_df[fs_df[process]>=1].index))\n",
    "        if method == 'outlier10':\n",
    "            Q3 = fs_df[process].quantile(0.75)\n",
    "            Q1 = fs_df[process].quantile(0.25)\n",
    "            IQR = Q3 - Q1\n",
    "            threshold = Q3 + 1.5*IQR\n",
    "            if len(fs_df[fs_df[process]>threshold].index) > 0:\n",
    "                fs.append(np.array(fs_df[fs_df[process]>threshold].index))\n",
    "            else:\n",
    "                fs.append(np.array(list(fs_df[process].sort_values(ascending=False)[:11].index)))\n",
    "        if method == 'outlier/Q3':\n",
    "            Q3 = fs_df[process].quantile(0.75)\n",
    "            Q1 = fs_df[process].quantile(0.25)\n",
    "            IQR = Q3 - Q1\n",
    "            threshold = Q3 + 1.5*IQR\n",
    "            if len(fs_df[fs_df[process]>threshold].index) > 0:\n",
    "                fs.append(np.array(fs_df[fs_df[process]>threshold].index))\n",
    "            else:\n",
    "                fs.append(np.array(fs_df[fs_df[process]>Q3].index))\n",
    "        if method == '10':\n",
    "            fs_list = list(fs_df[process].sort_values(ascending=False)[:11].index)\n",
    "            if column not in fs_list:\n",
    "                fs_list = fs_list[:10]\n",
    "                fs_list.append(column)\n",
    "            fs.append(fs_list)\n",
    "    return np.array(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791e955f",
   "metadata": {},
   "source": [
    "## 2.1. Classification with 11 (10 + self) best processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5917b165",
   "metadata": {},
   "source": [
    "### 2.1.1. Complete Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e45e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "\n",
    "reactome_hypergeometric_fs = process_selector(reactome_hypergeometric_fs_ar, '10')\n",
    "hyper_lgr_clf, hyper_lgr_proba_clf, hyper_best_parameters = classifiers.classifier(clf, parameters, reactome_hypergeometric, reactome_hypergeometric_test_index, reactome_hypergeometric_fs, pd.DataFrame(reactome_labels).transpose())\n",
    "hyper_lgr_clf.to_csv('../../models/apid_huri/process_hyper_lgr.csv', index=False)\n",
    "hyper_lgr_proba_clf.to_csv('../../models/apid_huri/process_hyper_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/hyper_best_parameters', 'w') as fout:\n",
    "    json.dump(hyper_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f242aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "reactome_rwr_fs = process_selector(reactome_rwr_fs_ar, '10')\n",
    "rwr_lgr_clf, rwr_lgr_proba_clf, rwr_best_parameters = classifiers.classifier(clf, parameters, reactome_rwr, reactome_rwr_test_index, reactome_rwr_fs, reactome_labels)\n",
    "rwr_lgr_clf.to_csv('../../models/apid_huri/process_rwr_lgr.csv', index=False)\n",
    "rwr_lgr_proba_clf.to_csv('../../models/apid_huri/process_rwr_lgr2.csv', index = False)\n",
    "with open('../../models/apid_huri/best_parameters/rwr_best_parameters', 'w') as fout:\n",
    "    json.dump(rwr_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91671af",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "reactome_closeness_fs = process_selector(reactome_closeness_fs_ar, '10')\n",
    "closeness_lgr_clf, closeness_lgr_proba_clf, closeness_best_parameters = classifiers.classifier(clf, parameters, reactome_closeness, reactome_closeness_test_index, reactome_closeness_fs, reactome_labels)\n",
    "closeness_lgr_clf.to_csv('../../models/apid_huri/process_closeness_lgr.csv', index=False)\n",
    "closeness_lgr_proba_clf.to_csv('../../models/apid_huri/process_closeness_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/closeness_best_parameters', 'w') as fout:\n",
    "    json.dump(closeness_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c11337",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "reactome_betweenness_fs = process_selector(reactome_betweenness_fs_ar, '10')\n",
    "betweenness_lgr_clf, betweenness_lgr_proba_clf, betweenness_best_parameters = classifiers.classifier(clf, parameters, reactome_betweenness, reactome_betweenness_test_index, reactome_betweenness_fs, reactome_labels)\n",
    "betweenness_lgr_clf.to_csv('../../models/apid_huri/process_betweenness_lgr.csv', index=False)\n",
    "betweenness_lgr_proba_clf.to_csv('../../models/apid_huri/process_betweenness_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/betweenness_best_parameters', 'w') as fout:\n",
    "    json.dump(betweenness_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b92c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "reactome_fraction_betweenness_fs = process_selector(reactome_fraction_betweenness_fs_ar, '10')\n",
    "fraction_betweenness_lgr_clf, fraction_betweenness_lgr_proba_clf, fraction_betweenness_best_parameters = classifiers.classifier(clf, parameters, reactome_fraction_betweenness, reactome_fraction_betweenness_test_index, reactome_fraction_betweenness_fs, pd.DataFrame(reactome_labels).transpose())\n",
    "fraction_betweenness_lgr_clf.to_csv('../../models/apid_huri/process_fraction_betweenness_lgr.csv', index=False)\n",
    "fraction_betweenness_lgr_proba_clf.to_csv('../../models/apid_huri/process_fraction_betweenness_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/fraction_betweenness_best_parameters', 'w') as fout:\n",
    "    json.dump(fraction_betweenness_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f1008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "bridge_lgr_clf, bridge_lgr_proba_clf, bridge_best_parameters = classifiers.classifier(clf, parameters, reactome_bridge, reactome_bridge_test_index, None, reactome_labels, related=True)\n",
    "bridge_lgr_clf.to_csv('../../models/apid_huri/process_bridge_lgr.csv', index=False)\n",
    "bridge_lgr_proba_clf.to_csv('../../models/apid_huri/process_bridge_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/bridge_best_parameters', 'w') as fout:\n",
    "    json.dump(bridge_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088635d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "scp_lgr_clf, scp_lgr_proba_clf, scp_best_parameters = classifiers.classifier(clf, parameters, reactome_scp, reactome_scp_test_index, None, reactome_labels, related=True)\n",
    "scp_lgr_clf.to_csv('../../models/apid_huri/process_scp_lgr.csv', index=False)\n",
    "scp_lgr_proba_clf.to_csv('../../models/apid_huri/process_scp_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/scp_best_parameters', 'w') as fout:\n",
    "    json.dump(scp_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f809b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "slb_lgr_clf, slb_lgr_proba_clf, slb_best_parameters = classifiers.classifier(clf, parameters, reactome_slb, reactome_slb_test_index, None, reactome_labels, related=True)\n",
    "slb_lgr_clf.to_csv('../../models/apid_huri/process_slb_lgr.csv', index=False)\n",
    "slb_lgr_proba_clf.to_csv('../../models/apid_huri/process_slb_lgr2.csv', index=False)\n",
    "with open('../../models/apid_huri/best_parameters/slb_best_parameters', 'w') as fout:\n",
    "    json.dump(slb_best_parameters, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352c66c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "hyper_lgr_clf3 = classifiers.classifier3(clf, hyper_best_parameters, reactome_hypergeometric, reactome_hypergeometric_test_index, reactome_hypergeometric_fs_ar, reactome_labels, hyper_lgr_proba_clf['threshold'].median())\n",
    "hyper_lgr_clf3.to_csv('../../models/apid_huri/process_hyper_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "rwr_lgr_clf3 = classifiers.classifier3(clf, rwr_best_parameters, reactome_rwr, reactome_rwr_test_index, reactome_rwr_fs_ar, reactome_labels, rwr_lgr_proba_clf['threshold'].median())\n",
    "rwr_lgr_clf3.to_csv('../../models/apid_huri/process_rwr_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02d79f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "closeness_lgr_clf3 = classifiers.classifier3(clf, closeness_best_parameters, reactome_closeness, reactome_closeness_test_index, reactome_closeness_fs_ar, reactome_labels, closeness_lgr_proba_clf['threshold'].median())\n",
    "closeness_lgr_clf3.to_csv('../../models/apid_huri/process_closeness_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f74b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "betweenness_lgr_clf3 = classifiers.classifier3(clf, betweenness_best_parameters, reactome_betweenness, reactome_betweenness_test_index, reactome_betweenness_fs_ar, reactome_labels, betweenness_lgr_proba_clf['threshold'].median())\n",
    "betweenness_lgr_clf3.to_csv('../../models/apid_huri/process_betweenness_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d8b0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "bridge_lgr_clf3 = classifiers.classifier3(clf, bridge_best_parameters, reactome_bridge, reactome_bridge_test_index, None, reactome_labels, bridge_lgr_proba_clf['threshold'].median(), related=True)\n",
    "bridge_lgr_clf3.to_csv('../../models/apid_huri/process_bridge_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2dff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "scp_lgr_clf3 = classifiers.classifier3(clf, scp_best_parameters, reactome_scp, reactome_scp_test_index, None, reactome_labels, scp_lgr_proba_clf['threshold'].median(), related=True)\n",
    "scp_lgr_clf3.to_csv('../../models/apid_huri/process_scp_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae4b159",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "slb_lgr_clf3 = classifiers.classifier3(clf, slb_best_parameters, reactome_slb, reactome_slb_test_index, None, reactome_labels, slb_lgr_proba_clf['threshold'].median(), related=True)\n",
    "slb_lgr_clf3.to_csv('../../models/apid_huri/process_slb_lgr3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72237216",
   "metadata": {},
   "source": [
    "### 2.1.2. Reduced Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9f7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "hyper_lgr_clf4, hyper_lgr_proba_clf4, hyper_lgr_clf4_bp = classifiers.reduced_classifiers(1, clf, parameters, ppi80_hyper_list, reactome_hypergeometric_80_test_index, reactome_hypergeometric_80_fs, reactome_labels_df)\n",
    "hyper_lgr_clf4.to_csv('../../models/apid_huri/process_hyper_80_lgr.csv', index=True)\n",
    "hyper_lgr_proba_clf4.to_csv('../../models/apid_huri/process_hyper_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/hyper_80_best_parameters', 'w') as fout:\n",
    "    json.dump(hyper_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a8d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "rwr_lgr_clf4, rwr_lgr_proba_clf4, rwr_lgr_clf4_bp = classifiers.reduced_classifiers(1, clf, parameters, ppi80_rwr_list, reactome_rwr_80_test_index, reactome_rwr_80_fs, reactome_labels_df)\n",
    "rwr_lgr_clf4.to_csv('../../models/apid_huri/process_rwr_80_lgr.csv', index=True)\n",
    "rwr_lgr_proba_clf4.to_csv('../../models/apid_huri/process_rwr_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/rwr_80_best_parameters', 'w') as fout:\n",
    "    json.dump(hyper_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17df9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "closeness_lgr_clf4, closeness_lgr_proba_clf4, closeness_lgr_clf4_bp = reduced_classifiers(1, clf, parameters, ppi80_closeness_list, reactome_closeness_80_test_index, reactome_closeness_80_fs, reactome_labels_df)\n",
    "closeness_lgr_clf4.to_csv('../../models/apid_huri/process_closeness_80_lgr.csv', index=True)\n",
    "closeness_lgr_proba_clf4.to_csv('../../models/apid_huri/process_closeness_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/closeness_80_best_parameters', 'w') as fout:\n",
    "    json.dump(closeness_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c89ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "betweenness_lgr_clf4, betweenness_lgr_proba_clf4, betweenness_lgr_clf4_bp = classifiers.reduced_classifiers(1, clf, parameters, ppi80_betweenness_list, reactome_betweenness_80_test_index, reactome_betweenness_80_fs_ar, label_list)\n",
    "betweenness_lgr_clf4.to_csv('../../models/apid_huri/process_betweenness_80_lgr.csv', index=True)\n",
    "betweenness_lgr_proba_clf4.to_csv('../../models/apid_huri/process_betweenness_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/betweenness_80_best_parameters', 'w') as fout:\n",
    "    json.dump(closeness_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f599b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "fraction_betweenness_lgr_clf4, fraction_betweenness_lgr_proba_clf4, fraction_betweenness_lgr_clf4_bp = classifiers.reduced_classifiers(1, clf, parameters, ppi80_fraction_betweenness_list, reactome_fraction_betweenness_80_test_index, reactome_fraction_betweenness_80_fs_ar, label_list)\n",
    "fraction_betweenness_lgr_clf4.to_csv('../../models/apid_huri/process_fraction_betweenness_80_lgr.csv', index=True)\n",
    "fraction_betweenness_lgr_proba_clf4.to_csv('../../models/apid_huri/process_fraction_betweenness_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/fraction_betweenness_80_best_parameters', 'w') as fout:\n",
    "    json.dump(fraction_betweenness_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ce5fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(classifiers)\n",
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "bridge_lgr_clf4, bridge_lgr_proba_clf4, bridge_lgr_clf4_bp = classifiers.reduced_classifiers(1, clf, parameters, ppi80_bridge_list, reactome_bridge_80_test_index, None, label_list, related=True)\n",
    "bridge_lgr_clf4.to_csv('../../models/apid_huri/process_bridge_80_lgr.csv', index=True)\n",
    "bridge_lgr_proba_clf4.to_csv('../../models/apid_huri/process_bridge_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/bridge_80_best_parameters', 'w') as fout:\n",
    "    json.dump(bridge_lgr_clf4_bp, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=22)\n",
    "parameters = [{'penalty':['l1','l2'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['liblinear'], 'max_iter':[10, 50, 100]}, \n",
    "              {'penalty':['l2', 'none'], 'C':[100, 10, 1.0, 0.1, 0.01],\n",
    "             'solver': ['sag', 'saga', 'newton-cg'], 'max_iter':[10, 50, 100]}]\n",
    "scp_lgr_clf4, scp_lgr_proba_clf4, scp_lgr_clf4_bp = reduced_classifiers(1, clf, parameters, ppi80_scp_list, reactome_scp_80_test_index, None, label_list)\n",
    "scp_lgr_clf4.to_csv('../../models/apid_huri/process_scp_80_lgr.csv', index=True)\n",
    "scp_lgr_proba_clf4.to_csv('../../models/apid_huri/process_scp_80_lgr2.csv', index=True)\n",
    "with open('../../models/apid_huri/best_parameters/scp_80_best_parameters', 'w') as fout:\n",
    "    json.dump(scp_lgr_clf4_bp, fout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
